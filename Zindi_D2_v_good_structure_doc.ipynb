{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este código é a implementação de um modelo de machine learning usado em uma competição de ciência de dados de uma empresa real, para classificar funcionários inadimplentes, para concessão de crédito."
      ],
      "metadata": {
        "id": "3ilYs88glcdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "path = '/content/default_train_set.csv'\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df_test = pd.read_csv('/content/Default_Test_Set.csv')\n",
        "\n",
        "df_economic = pd.read_csv('/content/economic_indicators.csv')"
      ],
      "metadata": {
        "id": "GK5QK5Fwt12L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separando o dataset entre teste e treino"
      ],
      "metadata": {
        "id": "ujs1F154lZRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# Divisão\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "lw_0qRYOgZKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "convertendo variáveis de data para datetime."
      ],
      "metadata": {
        "id": "o6r-ogRKl7Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['disbursement_date'] = pd.to_datetime(X_train['disbursement_date'])\n",
        "X_train['due_date'] = pd.to_datetime(X_train['due_date'])\n",
        "X_test['disbursement_date'] = pd.to_datetime(X_test['disbursement_date'])\n",
        "X_test['due_date'] = pd.to_datetime(X_test['due_date'])\n",
        "\n",
        "df_test['disbursement_date'] = pd.to_datetime(df_test['disbursement_date'])\n",
        "df_test['due_date'] = pd.to_datetime(df_test['due_date'])\n",
        "\n",
        "df_test['disbursement_date'] = df_test['disbursement_date'].apply(lambda date: date.toordinal())\n",
        "df_test['due_date'] = df_test['due_date'].apply(lambda date: date.toordinal())\n",
        "\n",
        "X_train['disbursement_date'] = X_train['disbursement_date'].apply(lambda date: date.toordinal())\n",
        "X_train['due_date'] = X_train['due_date'].apply(lambda date: date.toordinal())\n",
        "X_test['disbursement_date'] = X_test['disbursement_date'].apply(lambda date: date.toordinal())\n",
        "X_test['due_date'] = X_test['due_date'].apply(lambda date: date.toordinal())"
      ],
      "metadata": {
        "id": "uxNjuaY2BWZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aplicando feature engineering:\n",
        "\n",
        "# 1. data['Repayment_Percentage'] = data['Total_Amount_to_Repay'] / data['Total_Amount']\n",
        "\n",
        "Objetivo: Calcula a porcentagem do valor total que precisa ser reembolsado em relação ao valor total do empréstimo.\n",
        "Razão: Essa feature indica o peso do reembolso em relação ao valor original do empréstimo, o que pode ser um indicador importante de risco de inadimplência. Um valor mais alto sugere um custo maior para o tomador do empréstimo.\n",
        "# 2. data['Loan_Duration_to_Amount_Ratio'] = data['duration'] / data['Total_Amount']\n",
        "\n",
        "Objetivo: Calcula a relação entre a duração do empréstimo e o valor total do empréstimo.\n",
        "Razão: Essa feature busca capturar como a duração do empréstimo se relaciona com o valor total. Empréstimos de maior valor com prazos mais curtos podem representar um risco maior, enquanto empréstimos de menor valor com prazos longos podem ter um perfil de risco diferente.\n",
        "\n",
        "# 3. data['Profit_Margin'] = data['Total_Amount_to_Repay'] - data['Total_Amount']\n",
        "\n",
        "Objetivo: Calcula a margem de lucro do empréstimo, que é a diferença entre o valor total a ser reembolsado e o valor total do empréstimo.\n",
        "Razão: Essa feature representa o lucro obtido com o empréstimo. Uma margem de lucro maior pode indicar um empréstimo mais lucrativo, mas também pode estar associada a um risco maior de inadimplência.\n",
        "\n",
        "# 4. data['Adjusted_Profit_Margin'] = data['Profit_Margin'] / data['duration']\n",
        "\n",
        "Objetivo: Calcula a margem de lucro ajustada pela duração do empréstimo.\n",
        "Razão: Essa feature busca normalizar a margem de lucro, levando em consideração o tempo do empréstimo. Isso permite comparar a lucratividade de empréstimos com durações diferentes.\n",
        "\n",
        "# 5. data['Lender_Contribution_Ratio'] = data['Amount_Funded_By_Lender'] / data['Total_Amount']\n",
        "\n",
        "Objetivo: Calcula a proporção do valor total do empréstimo que foi financiada pelo credor.\n",
        "Razão: Essa feature indica o nível de participação do credor no empréstimo. Um valor mais alto sugere um maior comprometimento do credor com o empréstimo."
      ],
      "metadata": {
        "id": "JPWj0yk_mGBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(data):\n",
        "    data['Repayment_Percentage'] = data['Total_Amount_to_Repay'] / data['Total_Amount']\n",
        "    data['Loan_Duration_to_Amount_Ratio'] = data['duration'] / data['Total_Amount']\n",
        "    data['Profit_Margin'] = data['Total_Amount_to_Repay'] - data['Total_Amount']\n",
        "    data['Adjusted_Profit_Margin'] = data['Profit_Margin'] / data['duration']\n",
        "    data['Lender_Contribution_Ratio'] = data['Amount_Funded_By_Lender'] / data['Total_Amount']\n",
        "\n",
        "    # Conversões de datas\n",
        "    data['disbursement_date'] = pd.to_datetime(data['disbursement_date'])\n",
        "    data['due_date'] = pd.to_datetime(data['due_date'])\n",
        "    data['Days_to_Due'] = (data['due_date'] - data['disbursement_date']).dt.days\n",
        "\n",
        "    return data\n",
        "\n",
        "# Aplica separadamente para os dois conjuntos\n",
        "X_train = feature_engineering(X_train)\n",
        "X_test = feature_engineering(X_test)\n",
        "\n",
        "df_test = feature_engineering(df_test)\n"
      ],
      "metadata": {
        "id": "RpckXQbi_Jja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropando colunas que não serão usadas\n"
      ],
      "metadata": {
        "id": "BMzAe4J3m25q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.drop(columns=['ID','country_id', 'customer_id','tbl_loan_id','lender_id',\n",
        "                          'New_versus_Repeat'], inplace=True)\n",
        "\n",
        "X_test.drop(columns=['ID','country_id', 'customer_id','tbl_loan_id','lender_id',\n",
        "                          'New_versus_Repeat'], inplace=True)"
      ],
      "metadata": {
        "id": "RMeh_lUGCEQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop(columns=['country_id', 'customer_id','tbl_loan_id','lender_id',\n",
        "                          'New_versus_Repeat'], inplace=True)"
      ],
      "metadata": {
        "id": "h97NTnoQLw0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "categorizando a variavel lender_portion: a fração do valor total de um empréstimo que é financiada por um credor específico.\n",
        "\n",
        "e categorizando o repayment_percentage: representa a proporção do valor total que precisa ser reembolsado em relação ao valor total do empréstimo."
      ],
      "metadata": {
        "id": "3JxlM9R5nCqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_lender_portion(portion):\n",
        "    if portion > 0.5:\n",
        "        return 5\n",
        "    elif portion == 0.5:\n",
        "        return 4\n",
        "    elif portion < 0.5 and portion >= 0.3:\n",
        "        return 3\n",
        "    elif portion < 0.3 and portion >= 0.2:\n",
        "        return 2\n",
        "    elif portion < 0.2 and portion > 0.0:\n",
        "        return 1\n",
        "    elif portion == 0.0:\n",
        "        return 0\n",
        "\n",
        "X_train['Lender_portion_category'] = X_train['Lender_portion_Funded'].apply(categorize_lender_portion)\n",
        "X_test['Lender_portion_category'] = X_test['Lender_portion_Funded'].apply(categorize_lender_portion)\n",
        "df_test['Lender_portion_category'] = df_test['Lender_portion_Funded'].apply(categorize_lender_portion)\n",
        "\n",
        "# Categorizar Repayment_Percentage\n",
        "X_train['Repayment_Percentage'] = X_train['Total_Amount_to_Repay'] / X_train['Total_Amount']\n",
        "X_test['Repayment_Percentage'] = X_test['Total_Amount_to_Repay'] / X_test['Total_Amount']\n",
        "df_test['Repayment_Percentage'] = df_test['Total_Amount_to_Repay'] / df_test['Total_Amount']\n",
        "\n",
        "def categorize_repayment_percentage(percentage):\n",
        "    if percentage > 1.5:\n",
        "        return 3\n",
        "    elif percentage > 1.2:\n",
        "        return 2\n",
        "    elif percentage > 1.0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "X_train['Repayment_Category'] = X_train['Repayment_Percentage'].apply(categorize_repayment_percentage)\n",
        "X_test['Repayment_Category'] = X_test['Repayment_Percentage'].apply(categorize_repayment_percentage)\n",
        "df_test['Repayment_Category'] = df_test['Repayment_Percentage'].apply(categorize_repayment_percentage)\n",
        "\n",
        "X_train = pd.get_dummies(X_train, columns=['Lender_portion_category', 'Repayment_Category'], prefix=['LenderCat', 'RepayCat'])\n",
        "X_test = pd.get_dummies(X_test, columns=['Lender_portion_category', 'Repayment_Category'], prefix=['LenderCat', 'RepayCat'])\n",
        "df_test = pd.get_dummies(df_test, columns=['Lender_portion_category', 'Repayment_Category'], prefix=['LenderCat', 'RepayCat'])\n",
        "\n",
        "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)"
      ],
      "metadata": {
        "id": "cuWSNySEAUK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo um experimento. Criando uma sub amostragem no dataset da categoria alvo. para colocar as duas categorias com mesmo numero de entradas, a custo de cortar entradas da classe com maior amostragem. o experimento não funcionou bem, pois informações significativas da classe maior foram perdidas. não utilizei este método, mas deixei para fins de documentação."
      ],
      "metadata": {
        "id": "1Hd5Q9hTr2Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Função para subsamplear\n",
        "def balanced_subsample(X, y):\n",
        "\n",
        "    # Concatenar X_train e y_train para processar juntos\n",
        "    data = pd.concat([X, y], axis=1)\n",
        "\n",
        "    # Identificar as classes no y_train\n",
        "    min_class = y.value_counts().min()  # Pega o menor tamanho das classes\n",
        "\n",
        "    # Subsamplear cada classe para ter o mesmo tamanho\n",
        "    sampled = pd.concat([\n",
        "        resample(data[data[y.name] == label],  # Subsamplear para cada classe\n",
        "                 replace=False,               # Não queremos duplicar dados\n",
        "                 n_samples=min_class,         # Número de amostras para igualar as classes\n",
        "                 random_state=42)             # Controlar a aleatoriedade\n",
        "        for label in y.unique()\n",
        "    ])\n",
        "\n",
        "    X_balanced = sampled.drop(columns=y.name)\n",
        "    y_balanced = sampled[y.name]\n",
        "    return X_balanced, y_balanced\n",
        "\n",
        "X_train_balanced, y_train_balanced = balanced_subsample(X_train, y_train)\n",
        "\n",
        "# Verificar os tamanhos balanceados\n",
        "print(f\"Tamanhos após o subsampleamento:\\n{y_train_balanced.value_counts()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPLlD7ulF8oD",
        "outputId": "9e48e766-2066-479b-8c73-475bee08700e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanhos após o subsampleamento:\n",
            "target\n",
            "0    1006\n",
            "1    1006\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "criando variaveis contendo apenas numeros para o pre processamento."
      ],
      "metadata": {
        "id": "SyWcwFXismXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_var = X_train.select_dtypes(include=np.number).columns\n",
        "num_var_test = X_test.select_dtypes(include=np.number).columns\n",
        "num_var_df_test = df_test.select_dtypes(include=np.number).columns"
      ],
      "metadata": {
        "id": "mgin81xBMg-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "escalonamento padrão para as variaveis numéricas\n"
      ],
      "metadata": {
        "id": "ODDK0kF8n2Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_var])\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test[num_var_test])\n",
        "\n",
        "df_test_scaled = scaler.transform(df_test[num_var_test])\n"
      ],
      "metadata": {
        "id": "t6dLfimc_UOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementando o modelo random forest depois do pré processamento."
      ],
      "metadata": {
        "id": "6M0GFDxfn_Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Definir os hiperparâmetros a testar\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 300, 50),\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Inicializando o modelo de Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Realizando o Random Search com 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf, param_distributions=param_dist, n_iter=8, cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Treinando o modelo\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Melhores parâmetros encontrados\n",
        "print(f\"Melhores parâmetros: {random_search.best_params_}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_pred = random_search.predict(X_test_scaled)\n",
        "\n",
        "# Mostrar o F1 Score\n",
        "print(f\"F1 Score no conjunto de teste: {f1_score(y_test, y_pred)}\")\n",
        "\n",
        "# Imprimir classificação detalhada\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk10-iY6jh",
        "outputId": "c8c4623e-a67d-4d33-e325-29fd39538809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "5 fits failed out of a total of 40.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.99435573 0.99464704 0.99464705 0.99411903 0.99461064        nan\n",
            " 0.99391874 0.99393696]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "F1 Score no conjunto de teste: 0.8549019607843137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     13479\n",
            "           1       0.84      0.87      0.85       252\n",
            "\n",
            "    accuracy                           0.99     13731\n",
            "   macro avg       0.92      0.93      0.93     13731\n",
            "weighted avg       0.99      0.99      0.99     13731\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a acurácia deu muito alta, e não é métrica para se observar em um problema como esse, e sim a métrica precisão e recall. Isso porque as classes estão extremamente desbalanceadas, o que é normal em um dataset de indadimplencia ou, de fraudes. Há muito menos indadimplentes do que adimplentes normalmente.\n",
        "Por isso, o que estamos avaliando aqui é o precision e recall, que, para este dataset, foi de 0.84 e 0.87.  "
      ],
      "metadata": {
        "id": "qwH5eZKnoYB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui embaixo escolhi os melhores parametros para o random forest de forma aleatória a partir de um escopo pré definido de parâmetros. O algoritmo escolhe o melhor parametro do escopo para eu utilizar."
      ],
      "metadata": {
        "id": "73zVJoSnpJQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_best_params = {\n",
        "    'n_estimators': 50,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'sqrt',\n",
        "    'max_depth': None,\n",
        "    'bootstrap': False\n",
        "}\n",
        "\n",
        "# Inicializando o modelo Random Forest com os melhores parâmetros\n",
        "rf_best = RandomForestClassifier(**rf_best_params, random_state=42)\n",
        "\n",
        "# Treinando o modelo nos dados de treinamento\n",
        "rf_best.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazendo predições no conjunto de teste\n",
        "y_pred_3 = rf_best.predict(X_test_scaled)\n",
        "\n",
        "# Avaliando o modelo com F1 Score\n",
        "f1 = f1_score(y_test, y_pred_3)\n",
        "print(f\"F1 Score no conjunto de teste: {f1}\")\n",
        "\n",
        "# Imprimir classificação detalhada\n",
        "print(classification_report(y_test, y_pred_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St4QfZydaMTy",
        "outputId": "2f91a55b-2a95-41d2-b3c6-6683980705af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score no conjunto de teste: 0.8549019607843137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     13479\n",
            "           1       0.84      0.87      0.85       252\n",
            "\n",
            "    accuracy                           0.99     13731\n",
            "   macro avg       0.92      0.93      0.93     13731\n",
            "weighted avg       0.99      0.99      0.99     13731\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui preparo o modelo para ser exportado para fazer previsões com mais dados, com o objetivo de testar a robustez do modelo"
      ],
      "metadata": {
        "id": "poRWJdBzpvjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_comp = df_test_scaled\n",
        "predictions = rf_best.predict(X_test_comp)"
      ],
      "metadata": {
        "id": "8TccbyJ0vvoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_1 = pd.DataFrame({\n",
        "    'ID': df_test['ID'],\n",
        "    'target': predictions\n",
        "})\n",
        "\n",
        "submission_1.to_csv('submission_1.csv', index=False)"
      ],
      "metadata": {
        "id": "Sqyj_FeMUwYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
